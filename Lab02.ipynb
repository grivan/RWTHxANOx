{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "<img src=\"figures/svtLogo.png\"/>\n",
    "</div>\n",
    "<center><h1>Mathematical Optimization for Engineers</h1></center>\n",
    "<center><h2>Lab 2</h2></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\newcommand{\\mr}[1]{\\mathrm{#1}}\n",
    "\\newcommand{\\D}{\\displaystyle}\n",
    "\\newcommand{\\bm}[1]{\\text{\\mathbf $#1$}}\n",
    "\\newcommand{\\bx}{\\mathbf{ x}}\n",
    "\\newcommand{\\f}{\\mathbf{{f}}}\n",
    "\\newcommand{\\g}{\\mathbf{ g}}\n",
    "\\newcommand{\\h}{\\mathbf{ h}}\n",
    "\\newcommand{\\R}{\\mathbb R}\n",
    "\\newcommand{\\A}{\\mathbf{ A}}\n",
    "\\newcommand{\\br}{\\boldsymbol{r}}\n",
    "\\newcommand{\\bp}{\\boldsymbol{p}}\n",
    "\\newcommand{\\bnabla}{\\mathbf{\\nabla}}\n",
    "$$\n",
    "# Basic math \n",
    "In this lab, we will compute Jacobians, gradients and Hessian matrices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Jacobian\n",
    "Let $$\\bnabla \\f:\\R^n \\rightarrow \\R^m,\\,\\bx \\mapsto \\f(\\bx)$$be a continuously differentiable function, where\n",
    "$$\n",
    "\\bx = \\left(\\begin{array}{c}\n",
    "x_1 \\\\ \n",
    "\\vdots \\\\ \n",
    "x_n\n",
    "\\end{array} \\right) , \\qquad \\f(\\bx)  = \\left(\\begin{array}{c}\n",
    "f_1(\\bx) \\\\ \n",
    "\\vdots \\\\ \n",
    "f_m(\\bx) \n",
    "\\end{array} \\right).\n",
    "$$\n",
    "The Jacobian $\\f'(\\bx)$ is defined by the matrix\n",
    "$$\n",
    "\\f'(\\bx) = \\left(  \\begin{array}{ccc}\n",
    "\\frac{\\partial f_1(\\bx)}{\\partial x_1} & \\cdots & \\frac{\\partial f_1(\\bx)}{\\partial x_n} \\\\ \n",
    "\\vdots & \\ddots & \\vdots \\\\ \n",
    "\\frac{\\partial f_m(\\bx)}{\\partial x_1} & \\cdots & \\frac{\\partial f_m(\\bx)}{\\partial x_n}\n",
    "\\end{array}  \\right).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient\n",
    "\n",
    "Now, let $f:\\R^n \\rightarrow \\R,\\,\\bx \\mapsto f(\\bx)$ be a scalar-valued continuously differentiable function\n",
    "with vector-valued arguments.\n",
    "The gradient $\\bnabla f(\\bx)$ and Jacobian $f'(\\bx)$ are defined as the column vector and row vector, respectively,\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx)  = \\left(\\begin{array}{c}\n",
    "\t\\frac{\\partial f(\\bx)}{\\partial x_1} \\\\ \n",
    "\t\\vdots \\\\ \n",
    "\t\\frac{\\partial f(\\bx)}{\\partial x_n}\n",
    "\\end{array} \\right), \\qquad  f'(\\bx)  = \\left(\\begin{array}{ccc}  \n",
    "\\frac{\\partial f(\\bx)}{\\partial x_1} & \n",
    "\\cdots & \n",
    "\\frac{\\partial f(\\bx)}{\\partial x_n}\n",
    "\\end{array}\\right).\n",
    "$$\n",
    "\n",
    "Note that  $\\bnabla f(\\bx)^T=f'(\\bx)$.\n",
    "\n",
    "### Gradient of the scalar product of two functions\n",
    "\n",
    "Let $\\g,\\h:\\R^n\\rightarrow\\R^n$ be two continuously differentiable functions. We want to compute the\n",
    "gradient of $f:\\R^n\\rightarrow \\R,\\;\\bx \\mapsto f(\\bx) = \\g(\\bx)^T\\h(\\bx)$, where $\\bx\\in\\R^n$.\n",
    "We have\n",
    "\n",
    "$$\n",
    "f(\\bx) = \\g(\\bx)^T\\h(\\bx) = \\sum_{i=1}^{n} g_i(\\bx)h_i(\\bx).\n",
    "$$\n",
    "\n",
    "The derivative with respect to $x_j$ ($1 \\le j \\le n$) is computed by the application of the product rule\n",
    "\n",
    "\\begin{equation}\\label{eq:1}\n",
    "\\frac{\\partial f(\\bx)}{\\partial x_j} = \\sum_{i=1}^{n} \\left(\\frac{\\partial g_i(\\bx)}{\\partial x_j}h_i(\\bx)  +g_i(\\bx)\\frac{\\partial h_i(\\bx)}{\\partial x_j}\\right).\n",
    "\\end{equation}\n",
    "\n",
    "With the notations\n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\g(\\bx)}{\\partial x_j}   = \\left(\\begin{array}{c}\n",
    "\\frac{\\partial g_1(\\bx)}{\\partial x_j} \\\\ \n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial g_n(\\bx)}{\\partial x_j}\n",
    "\\end{array} \\right) \\quad \\text{and} \\quad \n",
    "\\frac{\\partial \\h(\\bx)}{\\partial x_j}   \n",
    "= \\left(\\begin{array}{c}\n",
    "\\frac{\\partial h_1(\\bx)}{\\partial x_j} \\\\ \n",
    "\\vdots \\\\ \n",
    "\\frac{\\partial h_n(\\bx)}{\\partial x_j}\n",
    "\\end{array} \\right), \\text{ respectively},\n",
    "$$\n",
    "\n",
    "we can rewrite the equation by\n",
    "\n",
    "$$\n",
    "\\frac{\\partial f(\\bx)}{\\partial x_j} = \\frac{\\partial \\g(\\bx)}{\\partial x_j} ^T \\h(\\bx) + \n",
    "\\g(\\bx)^T \\frac{\\partial \\h(\\bx)}{\\partial x_j}  = \\h(\\bx)^T\\frac{\\partial \\g(\\bx)}{\\partial x_j}\n",
    "+\\g(\\bx)^T \\frac{\\partial \\h(\\bx)}{\\partial x_j}\n",
    "$$\n",
    "\n",
    "Now, it is more less easy to see that the Jacobian of $f$ is given by\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx)^T = f'(\\bx) = \\h(\\bx)^T \\g'(\\bx) + \\g(\\bx)^T\\h'(\\bx).\n",
    "$$\n",
    "\n",
    "\n",
    "### Derivative of quadratic form\n",
    "If $\\A\\in\\R^{n\\times n}$ is a symmetric matrix, the function\n",
    "\n",
    "$$\n",
    "f:\\R^n\\rightarrow \\R,\\quad\\bx\\mapsto f(\\bx) = \\bx^T\\,\\A\\,\\bx\n",
    "$$ is called a quadratic form. With the definitions\n",
    "\n",
    "$$\n",
    "\\g(\\bx) := \\bx, \\quad \\text{and } \\h(\\bx):= \\A\\,\\bx,\n",
    "$$\n",
    "\n",
    "we have $f(\\bx) = \\g(\\bx)^T\\h(\\bx)$, i.e., exactly the situation as above.\n",
    "With $\\g'(\\bx) = \\mathbf{ I}$, where $\\mathbf{ I}$ denotes the unity matrix, and $\\h'(\\bx) = \\A$, it is more or less easy to see that the gradient of $f$ is given by\n",
    "\n",
    "\\begin{equation}\\label{eq:2}\n",
    "\\bnabla f(\\bx)^T = f'(\\bx) = (\\A\\,\\bx)^T \\mathbf{ I} + \\bx^T \\A =  \\bx^T \\A^T+ \\bx^T \\A = \\bx^T (\\A+\\A^T)\n",
    "\\end{equation}\n",
    "\n",
    "This formula is also valid for non-symmetric matrices. However, since we assumed $\\A$ to be symmetric, the formula simplifies further to\n",
    "\n",
    "$$\n",
    "\\bnabla f(\\bx)^T = 2\\,\\bx^T\\A, \\qquad \\text{or}\\quad \\bnabla f(\\bx) = 2\\,\\A\\,\\bx, \\text{ respectively}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical examples\n",
    "Let the function $f:\\R^2 \\rightarrow \\R$ be defined as\n",
    "$ f(x,y) = \\frac{1}{2} (x^2 + \\alpha y^2), \\alpha \\in \\R $\n",
    "\n",
    "Find all stationary points of the function $f$.\n",
    "\n",
    "\n",
    "Calculate the Hessian of the function $f$ for arbitrary $x$ and $y$.\n",
    "\n",
    "\n",
    "What are the eigenvalues of the Hessian of the function $f$ with respect to $x$ and $y$?\n",
    "\n",
    "\n",
    "Characterize the stationary points for positive and negative $\\alpha$.\n",
    "\n",
    "\n",
    "Characterize the convexity of the function for every $\\alpha$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rosenbrock function\n",
    "The Rosenbrock function is a famous test function used in optimization. \n",
    "It is defined by: \n",
    "$f:\\R^2 \\rightarrow \\R$\n",
    "$ f(x,y) = (a-x)^2 + b(y-x^2)^2 $ with $a=1, b=100$\n",
    "\n",
    "Find all stationary points of the function $f$.\n",
    "\n",
    "Calculate the Hessian of the function $f$ for the stationary points found.\n",
    "\n",
    "What are the eigenvalues of the Hessian of the function $f$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hessian computation for Rosenbrock\n",
    "import numpy as np\n",
    "hessian_rosenbrock = np.array([[802.0, -400.0], [-400.0, 200.0]])\n",
    "# compute the eigenvalues using numpy\n",
    "# your code here "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
